Covid19 - Mentorskool project Progress

/* Resources */


1. Data Catalog - https://docs.google.com/spreadsheets/d/12h8WQmD6u6IPCW63Y23zZR6NdCVO9396ANv8cVa6bCk/

1. Orginal Data Dictionary - https://drive.google.com/file/d/1f1B8pALq46zinX31Gne8K_ESqCDoQ1BR/

2. Modified data dictionary (for data that has an update cycle update, we can modify the above 					accordingly.) - https://docs.google.com/spreadsheets/d/1Ov7SQrRUI7CebOp2R2Rho6mOBri93fktmejR0klXsjI/

3. Duplicate Modified Data dictionary - https://docs.google.com/spreadsheets/d/1Ov7SQrRUI7CebOp2R2Rho6mOBri93fktmejR0klXsjI/

/* Plan  */

1. Have a data pipeline that provides access to a SQL server to the Analysts
2. Collaborate on Analysis - Present findings.

/* Data Pipeline */
Steps for creation.

1. Raw Data Ingestion Cloud Function Deployed - Gets triggered by a HTTP Request using cron job/cloud scheduler 1. -  fetch_raw_covid_api_data
	
	Note - If you add new data sources that are to be fetched on a schedule. Update this. 

	(No authentication Dont share)
	Trigger - https://us-central1-covid19-india-analysis-284814.cloudfunctions.net/fetch_raw_covid_api_data 
	
	Logs - "Function execution started"
			"Downloaded Daily Stats CSV at '/tmp/COVID_India_National.csv'"
		   "Downloaded Daily States Stats CSV at '/tmp/COVID_India_National.csv'"   
		   "Downloaded Daily Testing tats CSV at '/tmp/COVID_India_National.csv'"  
		   "Uploaded ['COVID_India_National.csv', 'COVID_India_State.csv', 'COVID_India_Test_data.csv'] to "mskl-data-lake" bucket."   
		   "Function execution took 4718 ms, finished with status code: 200"    

2. Create PostgreSQL CloudSQL instance and create covid-19-india server 
	
	instance id - covid19-india
	cloud_sql_connection_name = data-science-222913:asia-south1:covid19-india

	# Credentials
	db_user = 'postgres'
	db_password = 'mentorskool123'
	cloud_sql_ip = '35.200.129.164:5432'
	db_name = 'covid19-india'
	
	2nd User - client 
	password - client123

	Details(all lowest possible) : 
	machine selected - 1 shared vCPU
	0.6GB RAM
	10GB HDD
	NO Storage Updates
	NO automatic backups
	Single Zone

Two Options to create Database : 
	a. pg_dump of local server.
		1. Upload dump of local SQL server to Bucket - Cleaned folder.
		2. Import that dump to create Schema on Instance overview page. 
	b. Connect to SQL server instance and database using CloudSQL proxy and SQL Alchemy and use SQL alchemy 	to update schema. 

When Adding new data sources to SQL Server/Modifying Schema, can modify using helper notebook - 

3. Connecting to Server:
	a. Connect to CloudSQL instance using CloudSQL proxy and SQL Alchemy.
		1. Add service account with CloudSQL Client permission and export JSON key.
		2. Add location of Key to environment variable.
		3. Install the cloudSQL proxy. 
		4. Navigate to location of clouSQL proxy and connect to the server
		./cloud_sql_proxy -instances=data-science-222913:asia-south1:covid19-india=tcp:5432
		5. Connect Using SQL Alchemy Engine to proxy local server. 
		Helper Notebook

	b. Explore giving access to Public IPs(Not recommended for production instances.Should add as SQL 			Client and use CloudSQL Proxy). 
		1. add public IP of user to Master Instance->Connections->Public IP -> Add network
		2. Use SQL Alchemy to connect. Helper Notebook.

4. Cloud Function To Add Cleaned Data to SQL server triggered by a HTTP Request using Cron Job/Cloud 			scheduler 2. -  ingestion-clean-cloud-sql

	Loads the raw files from the buckets, cleans it and Uploads to CloudSQL Server. 

	(No authentication Dont share)
	Trigger - https://asia-south1-covid19-india-analysis-284814.cloudfunctions.net/ingestion-clean-cloud-sql 

	Steps for Permissions to connect with cloudSQl and bucket :

	
	Not much modification needed when adding data :
		a.load the raw CSV downloaded into /tmp/ as a pandas DF.
		b.clean it and make sure it is acc. to schema of table in DB:
		c.add_data_table(engine, 'table_name', Pandas_dataframe_ cleaned for ingestion)
	
	Logs- Function execution started
		199 Records in overall_stats
		Added 0 Records to table
		6045 Records in states_info
		Added 0 Records to table
		144 Records in testing_stats
		Added 0 Records to table
		Function execution took 2736 ms, finished with status code: 200

5. Created Cron Jobs that call [1] and [4] on a schedule.
	Permissions for cron job.